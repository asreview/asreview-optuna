{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asreview\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import synergy_dataset as sd\n",
    "from asreview.models.balancers import Balanced\n",
    "from asreview.models.classifiers import NaiveBayes\n",
    "from asreview.models.feature_extractors import Tfidf\n",
    "from asreview.models.queriers import Max\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Path to your SQLite3 database\n",
    "db_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(labels, num_priors, num_records):\n",
    "    return pd.Series(\n",
    "        labels.tolist() + np.zeros(num_records - len(labels) - num_priors).tolist()\n",
    "    )\n",
    "\n",
    "\n",
    "def n_query_extreme(results, n_records):\n",
    "    if n_records >= 10000:\n",
    "        if len(results) >= 10000:\n",
    "            return 10**5  # finish the run\n",
    "        if len(results) >= 1000:\n",
    "            return 1000\n",
    "        elif len(results) >= 100:\n",
    "            return 25\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if len(results) >= 1000:\n",
    "            return 100\n",
    "        elif len(results) >= 100:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Study, One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = {\"dataset_id\": \"Leenaars_2019\", \"prior_inclusions\": [2579, 16, 27], \"prior_exclusions\": [1868]}\n",
    "# study = {\"dataset_id\": \"Meijboom_2021\", \"prior_inclusions\": [531, 434, 129], \"prior_exclusions\": [119, 437, 362]}\n",
    "# study = {\"dataset_id\": \"Menon_2022\", \"prior_inclusions\": [392, 744], \"prior_exclusions\": [197]}\n",
    "# study = {\"dataset_id\": \"Oud_2018\", \"prior_inclusions\": [162, 256, 626], \"prior_exclusions\": [669, 866]}\n",
    "# study = {\"dataset_id\": \"Sep_2021\", \"prior_inclusions\": [160, 124, 42], \"prior_exclusions\": [178]}\n",
    "study = {\n",
    "    \"dataset_id\": \"Donners_2021\",\n",
    "    \"prior_inclusions\": [6, 235, 48, 81, 65, 98, 147],\n",
    "    \"prior_exclusions\": [9],\n",
    "}\n",
    "X = sd.Dataset(study[\"dataset_id\"]).to_frame().reset_index()\n",
    "priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "labels = X[\"label_included\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = \"ASReview2-full-tfidf-nb-3\"\n",
    "study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "params = study.best_trial.params\n",
    "\n",
    "alc = asreview.ActiveLearningCycle(\n",
    "    querier=Max(),\n",
    "    classifier=NaiveBayes(alpha=params[\"nb__alpha\"]),\n",
    "    balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "    feature_extractor=Tfidf(\n",
    "        stop_words=None,\n",
    "        ngram_range=(1, 2),\n",
    "        sublinear_tf=True,\n",
    "        max_df=params[\"tfidf__max_df\"],\n",
    "        min_df=params[\"tfidf__min_df\"],\n",
    "    ),\n",
    ")\n",
    "simulate_ndcg = asreview.Simulate(\n",
    "    X=X,\n",
    "    labels=labels,\n",
    "    cycles=[alc],\n",
    ")\n",
    "# Set priors\n",
    "simulate_ndcg.label(priors)\n",
    "# Start simulation\n",
    "simulate_ndcg.review()\n",
    "\n",
    "\n",
    "df_ndcg = simulate_ndcg._results.dropna(axis=0, subset=\"training_set\")\n",
    "labels_ndcg = pad_labels(df_ndcg[\"label\"].reset_index(drop=True), len(priors), len(X))\n",
    "recall_ndcg = labels_ndcg.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = \"ASReview2-full-nb-1\"\n",
    "study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "params = study.best_trial.params\n",
    "\n",
    "alc = asreview.ActiveLearningCycle(\n",
    "    querier=Max(),\n",
    "    classifier=NaiveBayes(alpha=params[\"alpha\"]),\n",
    "    balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "    feature_extractor=Tfidf(\n",
    "        stop_words=None,\n",
    "        ngram_range=(1, 2),\n",
    "        sublinear_tf=True,\n",
    "        max_df=params[\"tfidf__max_df\"],\n",
    "        min_df=params[\"tfidf__min_df\"],\n",
    "    ),\n",
    ")\n",
    "simulate_loss = asreview.Simulate(\n",
    "    X=X,\n",
    "    labels=labels,\n",
    "    cycles=[alc],\n",
    ")\n",
    "# Set priors\n",
    "simulate_loss.label(priors)\n",
    "# Start simulation\n",
    "simulate_loss.review()\n",
    "\n",
    "df_loss = simulate_loss._results.dropna(axis=0, subset=\"training_set\")\n",
    "labels_loss = pad_labels(df_loss[\"label\"].reset_index(drop=True), len(priors), len(X))\n",
    "recall_loss = labels_loss.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alc = asreview.ActiveLearningCycle(\n",
    "    querier=Max(),\n",
    "    classifier=NaiveBayes(alpha=3.822),\n",
    "    balancer=Balanced(ratio=1.2),\n",
    "    feature_extractor=Tfidf(stop_words=\"english\", ngram_range=(1, 1)),\n",
    ")\n",
    "simulate_old = asreview.Simulate(\n",
    "    X=X,\n",
    "    labels=labels,\n",
    "    cycles=[alc],\n",
    ")\n",
    "# Set priors\n",
    "simulate_old.label(priors)\n",
    "# Start simulation\n",
    "simulate_old.review()\n",
    "\n",
    "df_old = simulate_old._results.dropna(axis=0, subset=\"training_set\")\n",
    "labels_old = pad_labels(df_old[\"label\"].reset_index(drop=True), len(priors), len(X))\n",
    "recall_old = labels_old.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame({\"loss\": recall_loss, \"gain\": recall_ndcg, \"old\": recall_old})\n",
    "\n",
    "combined.plot()\n",
    "plt.savefig(\"recall_comp.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean of Multiple Studies, One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Appenzeller-Herzog_2019\"\n",
    "studies = pd.read_json(\"synergy_studies_full_val.jsonl\", lines=True)\n",
    "studies = studies[studies[\"dataset_id\"] == dataset_name]\n",
    "recalls_ndcg = []\n",
    "recalls_loss = []\n",
    "recalls_old = []\n",
    "\n",
    "for _, study in studies.iterrows():\n",
    "    X = sd.Dataset(study[\"dataset_id\"]).to_frame().reset_index()\n",
    "    priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "    labels = X[\"label_included\"]\n",
    "    study_name = \"ASReview2-full-tfidf-nb-3\"\n",
    "    study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "    params = study.best_trial.params\n",
    "\n",
    "    alc = asreview.ActiveLearningCycle(\n",
    "        querier=Max(),\n",
    "        classifier=NaiveBayes(alpha=params[\"nb__alpha\"]),\n",
    "        balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "        feature_extractor=Tfidf(\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            sublinear_tf=True,\n",
    "            max_df=params[\"tfidf__max_df\"],\n",
    "            min_df=params[\"tfidf__min_df\"],\n",
    "        ),\n",
    "    )\n",
    "    simulate_ndcg = asreview.Simulate(\n",
    "        X=X,\n",
    "        labels=labels,\n",
    "        cycles=[alc],\n",
    "    )\n",
    "    # Set priors\n",
    "    simulate_ndcg.label(priors)\n",
    "    # Start simulation\n",
    "    simulate_ndcg.review()\n",
    "\n",
    "    df_ndcg = simulate_ndcg._results.dropna(axis=0, subset=\"training_set\")\n",
    "    labels_ndcg = pad_labels(\n",
    "        df_ndcg[\"label\"].reset_index(drop=True), len(priors), len(X)\n",
    "    )\n",
    "    recalls_ndcg.append(labels_ndcg.cumsum())\n",
    "\n",
    "for _, study in studies.iterrows():\n",
    "    X = sd.Dataset(study[\"dataset_id\"]).to_frame().reset_index()\n",
    "    priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "    labels = X[\"label_included\"]\n",
    "    study_name = \"ASReview2-full-nb-1\"\n",
    "    study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "    params = study.best_trial.params\n",
    "\n",
    "    alc = asreview.ActiveLearningCycle(\n",
    "        querier=Max(),\n",
    "        classifier=NaiveBayes(alpha=params[\"alpha\"]),\n",
    "        balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "        feature_extractor=Tfidf(\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            sublinear_tf=True,\n",
    "            max_df=params[\"tfidf__max_df\"],\n",
    "            min_df=params[\"tfidf__min_df\"],\n",
    "        ),\n",
    "    )\n",
    "    simulate_loss = asreview.Simulate(\n",
    "        X=X,\n",
    "        labels=labels,\n",
    "        cycles=[alc],\n",
    "    )\n",
    "    # Set priors\n",
    "    simulate_loss.label(priors)\n",
    "    # Start simulation\n",
    "    simulate_loss.review()\n",
    "\n",
    "    df_loss = simulate_loss._results.dropna(axis=0, subset=\"training_set\")\n",
    "    labels_loss = pad_labels(\n",
    "        df_loss[\"label\"].reset_index(drop=True), len(priors), len(X)\n",
    "    )\n",
    "    recalls_loss.append(labels_loss.cumsum())\n",
    "\n",
    "for _, study in studies.iterrows():\n",
    "    X = sd.Dataset(study[\"dataset_id\"]).to_frame().reset_index()\n",
    "    priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "    labels = X[\"label_included\"]\n",
    "    alc = asreview.ActiveLearningCycle(\n",
    "        querier=Max(),\n",
    "        classifier=NaiveBayes(alpha=3.822),\n",
    "        balancer=Balanced(ratio=3),\n",
    "        feature_extractor=Tfidf(stop_words=\"english\", ngram_range=(1, 1)),\n",
    "    )\n",
    "    simulate_old = asreview.Simulate(\n",
    "        X=X,\n",
    "        labels=labels,\n",
    "        cycles=[alc],\n",
    "    )\n",
    "    # Set priors\n",
    "    simulate_old.label(priors)\n",
    "    # Start simulation\n",
    "    simulate_old.review()\n",
    "\n",
    "    df_old = simulate_old._results.dropna(axis=0, subset=\"training_set\")\n",
    "    labels_old = pad_labels(df_old[\"label\"].reset_index(drop=True), len(priors), len(X))\n",
    "    recalls_old.append(labels_old.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.array(x) for x in recalls_loss]\n",
    "new_recalls_loss = [np.mean(k) for k in zip(*arrays)]\n",
    "\n",
    "arrays = [np.array(x) for x in recalls_ndcg]\n",
    "new_recalls_ndcg = [np.mean(k) for k in zip(*arrays)]\n",
    "\n",
    "arrays = [np.array(x) for x in recalls_old]\n",
    "new_recalls_old = [np.mean(k) for k in zip(*arrays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(\n",
    "    {\"loss\": new_recalls_loss, \"gain\": new_recalls_ndcg, \"old\": new_recalls_old}\n",
    ")\n",
    "\n",
    "combined.plot()\n",
    "plt.savefig(f\"recall_comp_{dataset_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean of Multiple Studies, All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = pd.read_json(\"synergy_studies_full_val.jsonl\", lines=True)\n",
    "studies_filtered = (\n",
    "    studies.sort_values(\"dataset_id\")\n",
    "    .groupby(\"dataset_id\")\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "report_order = studies_filtered[\"dataset_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_ndcg = []\n",
    "\n",
    "opt_study_name = \"ASReview2-full-tfidf-nb-3\"\n",
    "opt_study = optuna.load_study(study_name=opt_study_name, storage=db_path)\n",
    "params = opt_study.best_trial.params\n",
    "for dataset_name in report_order:\n",
    "    if dataset_name == \"Moran_2021_corrected\":\n",
    "        X = pd.read_csv(\"./datasets/Moran_2021_corrected_shuffled_raw.csv\")\n",
    "    else:\n",
    "        X = sd.Dataset(dataset_name).to_frame().reset_index()\n",
    "\n",
    "    labels = X[\"label_included\"]\n",
    "\n",
    "    for _, study in studies_filtered[\n",
    "        studies_filtered[\"dataset_id\"] == dataset_name\n",
    "    ].iterrows():\n",
    "        priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "\n",
    "        alc = asreview.ActiveLearningCycle(\n",
    "            querier=Max(),\n",
    "            classifier=NaiveBayes(alpha=params[\"nb__alpha\"]),\n",
    "            balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "            feature_extractor=Tfidf(\n",
    "                stop_words=None,\n",
    "                ngram_range=(1, 2),\n",
    "                sublinear_tf=True,\n",
    "                max_df=params[\"tfidf__max_df\"],\n",
    "                min_df=params[\"tfidf__min_df\"],\n",
    "            ),\n",
    "            n_query=lambda results: n_query_extreme(results, X.shape[0]),\n",
    "        )\n",
    "\n",
    "        simulate_ndcg = asreview.Simulate(X=X, labels=labels, cycles=[alc])\n",
    "        simulate_ndcg.label(priors)\n",
    "        simulate_ndcg.review()\n",
    "\n",
    "        df_ndcg = simulate_ndcg._results.dropna(axis=0, subset=\"training_set\")\n",
    "        labels_ndcg = pad_labels(\n",
    "            df_ndcg[\"label\"].reset_index(drop=True), len(priors), len(X)\n",
    "        )\n",
    "        recalls_ndcg.append(labels_ndcg.cumsum())\n",
    "\n",
    "# Save intermediate results\n",
    "pd.DataFrame(recalls_ndcg).to_csv(\"recalls_ndcg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_loss = []\n",
    "\n",
    "opt_study_name = \"ASReview2-full-nb-1\"\n",
    "opt_study = optuna.load_study(study_name=opt_study_name, storage=db_path)\n",
    "params = opt_study.best_trial.params\n",
    "\n",
    "for dataset_name in report_order:\n",
    "    if dataset_name == \"Moran_2021_corrected\":\n",
    "        X = pd.read_csv(\"./datasets/Moran_2021_corrected_shuffled_raw.csv\")\n",
    "    else:\n",
    "        X = sd.Dataset(dataset_name).to_frame().reset_index()\n",
    "\n",
    "    labels = X[\"label_included\"]\n",
    "\n",
    "    for _, study in studies_filtered[\n",
    "        studies_filtered[\"dataset_id\"] == dataset_name\n",
    "    ].iterrows():\n",
    "        priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "\n",
    "        alc = asreview.ActiveLearningCycle(\n",
    "            querier=Max(),\n",
    "            classifier=NaiveBayes(alpha=params[\"alpha\"]),\n",
    "            balancer=Balanced(ratio=params[\"ratio\"]),\n",
    "            feature_extractor=Tfidf(\n",
    "                stop_words=None,\n",
    "                ngram_range=(1, 2),\n",
    "                sublinear_tf=True,\n",
    "                max_df=params[\"tfidf__max_df\"],\n",
    "                min_df=params[\"tfidf__min_df\"],\n",
    "            ),\n",
    "            n_query=lambda results: n_query_extreme(results, X.shape[0]),\n",
    "        )\n",
    "\n",
    "        simulate_loss = asreview.Simulate(X=X, labels=labels, cycles=[alc])\n",
    "        simulate_loss.label(priors)\n",
    "        simulate_loss.review()\n",
    "\n",
    "        df_loss = simulate_loss._results.dropna(axis=0, subset=\"training_set\")\n",
    "        labels_loss = pad_labels(\n",
    "            df_loss[\"label\"].reset_index(drop=True), len(priors), len(X)\n",
    "        )\n",
    "        recalls_loss.append(labels_loss.cumsum())\n",
    "\n",
    "# Save intermediate results\n",
    "pd.DataFrame(recalls_loss).to_csv(\"recalls_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Params, ASReview 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_old = []\n",
    "\n",
    "for dataset_name in report_order:\n",
    "    if dataset_name == \"Moran_2021_corrected\":\n",
    "        X = pd.read_csv(\"./datasets/Moran_2021_corrected_shuffled_raw.csv\")\n",
    "    else:\n",
    "        X = sd.Dataset(dataset_name).to_frame().reset_index()\n",
    "\n",
    "    labels = X[\"label_included\"]\n",
    "\n",
    "    for _, study in studies_filtered[\n",
    "        studies_filtered[\"dataset_id\"] == dataset_name\n",
    "    ].iterrows():\n",
    "        priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "\n",
    "        alc = asreview.ActiveLearningCycle(\n",
    "            querier=Max(),\n",
    "            classifier=NaiveBayes(alpha=3.822),\n",
    "            balancer=Balanced(ratio=3),\n",
    "            feature_extractor=Tfidf(stop_words=\"english\", ngram_range=(1, 1)),\n",
    "            n_query=lambda results: n_query_extreme(results, X.shape[0]),\n",
    "        )\n",
    "\n",
    "        simulate_old = asreview.Simulate(X=X, labels=labels, cycles=[alc])\n",
    "        simulate_old.label(priors)\n",
    "        simulate_old.review()\n",
    "\n",
    "        df_old = simulate_old._results.dropna(axis=0, subset=\"training_set\")\n",
    "        labels_old = pad_labels(\n",
    "            df_old[\"label\"].reset_index(drop=True), len(priors), len(X)\n",
    "        )\n",
    "        recalls_old.append(labels_old.cumsum())\n",
    "\n",
    "# Save intermediate results\n",
    "pd.DataFrame(recalls_old).to_csv(\"recalls_old.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = pd.read_json(\"synergy_studies_full_val.jsonl\", lines=True)\n",
    "studies_filtered = (\n",
    "    studies.sort_values(\"dataset_id\")\n",
    "    .groupby(\"dataset_id\")\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Load recall CSVs and ensure matching row counts\n",
    "recall_files = [\n",
    "    \"recalls_ndcg.csv\",\n",
    "    \"recalls_loss.csv\",\n",
    "    \"recalls_old.csv\",\n",
    "]\n",
    "recall_types = [\"NDCG\", \"Loss\", \"Old\"]\n",
    "\n",
    "df_recalls = [pd.read_csv(f) for f in recall_files]\n",
    "\n",
    "# Add dataset name and recall type\n",
    "for df, recall_type in zip([df_ndcg, df_loss, df_old], [\"NDCG\", \"Loss\", \"Old\"]):\n",
    "    df[\"dataset_name\"] = studies_filtered[\"dataset_id\"].values\n",
    "    df[\"type\"] = recall_type\n",
    "    df[\"prior_inclusions\"] = studies_filtered[\"prior_inclusions\"].apply(len)\n",
    "    df[\"prior_exclusions\"] = studies_filtered[\"prior_exclusions\"].apply(len)\n",
    "\n",
    "# Combine recall data\n",
    "df_all = pd.concat([df_ndcg, df_loss, df_old], ignore_index=True)\n",
    "\n",
    "# Compute total relevant counts per dataset\n",
    "total_relevant_dict = {\n",
    "    dataset_id: pd.read_csv(f\"./datasets/{dataset_id}_shuffled_raw.csv\")[\n",
    "        \"label_included\"\n",
    "    ].sum()\n",
    "    if dataset_id == \"Moran_2021_corrected\"\n",
    "    else sd.Dataset(dataset_id).to_frame()[\"label_included\"].sum()\n",
    "    for dataset_id in studies_filtered[\"dataset_id\"].unique()\n",
    "}\n",
    "\n",
    "# Melt dataframe\n",
    "df_all_melted = df_all.melt(\n",
    "    id_vars=[\"dataset_name\", \"type\", \"prior_inclusions\", \"prior_exclusions\"],\n",
    "    var_name=\"step\",\n",
    "    value_name=\"recall\",\n",
    ").dropna()\n",
    "\n",
    "# Convert step to numeric\n",
    "df_all_melted[\"step\"] = df_all_melted[\"step\"].astype(int)\n",
    "\n",
    "# Calculate total relevant items\n",
    "df_all_melted[\"total_relevant\"] = df_all_melted[\"dataset_name\"].map(total_relevant_dict)\n",
    "\n",
    "# Recall normalization\n",
    "df_all_melted[\"relative_recall\"] = df_all_melted[\"recall\"] / (\n",
    "    df_all_melted[\"total_relevant\"] - df_all_melted[\"prior_inclusions\"]\n",
    ")\n",
    "\n",
    "# Normalize step values to a common scale [0,1]\n",
    "df_all_melted[\"relative_step\"] = df_all_melted.groupby([\"dataset_name\", \"type\"])[\n",
    "    \"step\"\n",
    "].transform(lambda x: x / x.max())\n",
    "\n",
    "# Interpolation of normalized recall to a common x-axis\n",
    "x_new = np.linspace(0, 1, 1000)  # 1000 evenly spaced points for smooth curves\n",
    "\n",
    "\n",
    "interpolated_data = []\n",
    "for (dataset, recall_type), group in df_all_melted.groupby([\"dataset_name\", \"type\"]):\n",
    "    group = (\n",
    "        group.sort_values(\"relative_step\")\n",
    "        .groupby(\"relative_step\", as_index=False)[\"relative_recall\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    x, y = group[\"relative_step\"].values, group[\"relative_recall\"].values\n",
    "    f = interp1d(x, y, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    y_new = f(x_new)\n",
    "\n",
    "    interpolated_data.extend(\n",
    "        {\n",
    "            \"dataset_name\": dataset,\n",
    "            \"type\": recall_type,\n",
    "            \"relative_step\": step,\n",
    "            \"relative_recall\": recall,\n",
    "        }\n",
    "        for step, recall in zip(x_new, y_new)\n",
    "    )\n",
    "\n",
    "# Create DataFrame from interpolated results\n",
    "df_interpolated = pd.DataFrame(interpolated_data)\n",
    "\n",
    "# Compute the mean recall per dataset and recall type\n",
    "df_grouped = (\n",
    "    df_all_melted.groupby([\"dataset_name\", \"type\", \"relative_step\"])[\"relative_recall\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid size\n",
    "rows, cols = 5, 5\n",
    "datasets = df_grouped[\"dataset_name\"].unique()\n",
    "\n",
    "# Create PDF to store all plots\n",
    "with PdfPages(\"recall_comparison.pdf\") as pdf:\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))  # Adjust figure size\n",
    "    axes = axes.flatten()  # Flatten for easy iteration\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        ax = axes[i]  # Get subplot axis\n",
    "        df_subset = df_grouped[df_grouped[\"dataset_name\"] == dataset]\n",
    "\n",
    "        # Plot mean recall with standard deviation as shaded area\n",
    "        sns.lineplot(\n",
    "            data=df_subset,\n",
    "            x=\"relative_step\",\n",
    "            y=\"relative_recall\",\n",
    "            hue=\"type\",\n",
    "            ax=ax,\n",
    "            legend=True if i == 0 else False,\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Proportion of Documents\")\n",
    "        ax.set_ylabel(\"Mean Recall\")\n",
    "        ax.set_title(f\"{dataset}\")\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(fig)  # Save the entire grid as one page in the PDF\n",
    "    plt.close(fig)  # Close figure to free memory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asreview-2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
