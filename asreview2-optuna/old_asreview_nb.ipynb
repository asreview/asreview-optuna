{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from asreview import ASReviewData, ASReviewProject, open_state\n",
    "from asreview.models.balance import DoubleBalance\n",
    "from asreview.models.classifiers import NaiveBayesClassifier\n",
    "from asreview.models.feature_extraction import Tfidf\n",
    "from asreview.models.query import MaxQuery\n",
    "from asreview.review import ReviewSimulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(labels, num_priors, num_records):\n",
    "    return pd.Series(\n",
    "        labels.tolist() + np.zeros(num_records - len(labels) - num_priors).tolist()\n",
    "    )\n",
    "\n",
    "\n",
    "def n_query_extreme(results, n_records):\n",
    "    if n_records >= 10000:\n",
    "        if len(results) >= 10000:\n",
    "            return 10**5  # finish the run\n",
    "        if len(results) >= 1000:\n",
    "            return 1000\n",
    "        elif len(results) >= 100:\n",
    "            return 25\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if len(results) >= 1000:\n",
    "            return 100\n",
    "        elif len(results) >= 100:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = pd.read_json(\"synergy_studies_full_val.jsonl\", lines=True)\n",
    "report_order = sorted(set(studies[\"dataset_id\"]))\n",
    "\n",
    "for dataset_name in report_order:\n",
    "    dataset_studies = studies[studies[\"dataset_id\"] == dataset_name]\n",
    "    if dataset_name == \"Moran_2021_corrected\":\n",
    "        file_path = \"./datasets/Moran_2021_corrected_shuffled_raw.csv\"\n",
    "        data_obj = ASReviewData.from_file(file_path)\n",
    "    else:\n",
    "        file_path = f\"./datasets/synergy_dataset/{dataset_name}.csv\"\n",
    "        data_obj = ASReviewData.from_file(file_path)\n",
    "\n",
    "    dataset_studies = dataset_studies.head(5)\n",
    "    for i, study in dataset_studies.iterrows():\n",
    "        priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "\n",
    "        project_path = Path(\"asreview_old_tmp\", f\"{dataset_name}-{i}\")\n",
    "        project_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        project = ASReviewProject.create(\n",
    "            project_path=project_path / \"api_simulation\",\n",
    "            project_id=\"api_example\",\n",
    "            project_mode=\"simulate\",\n",
    "            project_name=\"api_example\",\n",
    "        )\n",
    "\n",
    "        project.add_dataset(\"../../../../\" + file_path)\n",
    "\n",
    "        # Select models to use\n",
    "        train_model = NaiveBayesClassifier()\n",
    "        query_model = MaxQuery()\n",
    "        balance_model = DoubleBalance()\n",
    "        feature_model = Tfidf()\n",
    "\n",
    "        # Initialize the simulation reviewer\n",
    "        reviewer = ReviewSimulate(\n",
    "            as_data=data_obj,\n",
    "            model=train_model,\n",
    "            query_model=query_model,\n",
    "            balance_model=balance_model,\n",
    "            feature_model=feature_model,\n",
    "            n_instances=1,\n",
    "            project=project,\n",
    "            n_prior_included=len(study[\"prior_inclusions\"]),\n",
    "            n_prior_excluded=len(study[\"prior_exclusions\"]),\n",
    "            prior_indices=priors,\n",
    "        )\n",
    "\n",
    "        reviewer.review()\n",
    "        # Finish and export the project, and cleanup files\n",
    "        project.export(f\"asreview_old_files/{dataset_name}-{i}.asreview\")\n",
    "        shutil.rmtree(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "2865    0\n",
      "2866    0\n",
      "2867    0\n",
      "2868    0\n",
      "2869    0\n",
      "Length: 2870, dtype: int64\n",
      "0       0\n",
      "1       1\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2861    0\n",
      "2862    0\n",
      "2863    0\n",
      "2864    0\n",
      "2865    0\n",
      "Length: 2866, dtype: int64\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "2862    0\n",
      "2863    0\n",
      "2864    0\n",
      "2865    0\n",
      "2866    0\n",
      "Length: 2867, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2864    0\n",
      "2865    0\n",
      "2866    0\n",
      "2867    0\n",
      "2868    0\n",
      "Length: 2869, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "2864    0\n",
      "2865    0\n",
      "2866    0\n",
      "2867    0\n",
      "2868    0\n",
      "Length: 2869, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4868    0\n",
      "4869    0\n",
      "4870    0\n",
      "4871    0\n",
      "4872    0\n",
      "Length: 4873, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4870    0\n",
      "4871    0\n",
      "4872    0\n",
      "4873    0\n",
      "4874    0\n",
      "Length: 4875, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "4863    0\n",
      "4864    0\n",
      "4865    0\n",
      "4866    0\n",
      "4867    0\n",
      "Length: 4868, dtype: int64\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4869    0\n",
      "4870    0\n",
      "4871    0\n",
      "4872    0\n",
      "4873    0\n",
      "Length: 4874, dtype: int64\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4869    0\n",
      "4870    0\n",
      "4871    0\n",
      "4872    0\n",
      "4873    0\n",
      "Length: 4874, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "studies = pd.read_json(\"synergy_studies_full_val.jsonl\", lines=True)\n",
    "report_order = sorted(set(studies[\"dataset_id\"]))\n",
    "\n",
    "recalls_old = []\n",
    "\n",
    "for dataset_name in report_order:\n",
    "    dataset_studies = studies[studies[\"dataset_id\"] == dataset_name]\n",
    "    dataset_studies = dataset_studies.head(5)\n",
    "\n",
    "    for i, study in dataset_studies.iterrows():\n",
    "        if study[\"dataset_id\"] == \"Appenzeller-Herzog_2019\" or study[\"dataset_id\"] == \"Bos_2018\":\n",
    "            priors = study[\"prior_inclusions\"] + study[\"prior_exclusions\"]\n",
    "\n",
    "            with open_state(f\"asreview_old_files/{dataset_name}-{i}.asreview\") as state:\n",
    "                df = state.get_dataset()\n",
    "                num_records = len(df)\n",
    "                df.drop(df[df[\"training_set\"] < 0].index, axis=0, inplace=True)\n",
    "                labels_old = pad_labels(\n",
    "                    df[\"label\"].reset_index(drop=True),\n",
    "                    len(priors),\n",
    "                    num_records,\n",
    "                )\n",
    "                recalls_old.append(labels_old.cumsum())\n",
    "\n",
    "pd.DataFrame(recalls_old).to_csv(\"recalls_old_1.6.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asreview-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
